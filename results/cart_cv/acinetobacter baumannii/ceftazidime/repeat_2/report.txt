Kover Learning Report
=====================

Running time: 0:38:27.692183

Configuration:
--------------
authorized_rules: 
bound_delta: 0.05
bound_max_genome_size: 10461658
class_importance: ['0.25', '0.5', '0.75', '1.0']
criterion: ['gini']
dataset: /scratch/adrouin/patric_data/single_species_datasets/ceftazidime___-3225223558739261696/dataset.kover
hp_choice: cv
max_depth: [20]
min_samples_split: [2]
n_cpu: 2
output_dir: /scratch/adrouin/patric_experiments/single_species_datasets/cart_cv/ceftazidime___-3225223558739261696/train_0.800_seed_1_10_folds
progress: False
split: train_0.800_seed_1_10_folds
verbose: False

Data summary:
-------------
Dataset file: /scratch/adrouin/patric_data/single_species_datasets/ceftazidime___-3225223558739261696/dataset.kover
Dataset UUID: 9991fcb4-095d-11e8-81b5-001b2193b764
Phenotype: Ceftazidime___Acinetobacter_Baumannii___Metadata_Date_2018-02-03
Split: train_0.800_seed_1_10_folds
Number of genomes used for training: 222 (Group sensitive: 21, Group resistant: 201)
Number of genomes used for testing: 55 (Group sensitive: 7, Group resistant: 48)

Hyperparameter Values:
----------------------
Selection strategy: 10-fold cross-validation (score = 0.01818)
Criterion: gini
Class importance: class sensitive: 0.250, class resistant: 0.500
Maximum tree depth: 20
Minimum samples to split a node (examples): 2.000
Pruning alpha: 0.00409468

Metrics (training data)
-----------------------
Error Rate: 0.00901
Sensitivity: 1.0
Specificity: 0.90476
Precision: 0.99015
Recall: 1.0
F1 Score: 0.99505
True Positives: 201.0
True Negatives: 19.0
False Positives: 2.0
False Negatives: 0.0

Metrics (testing data)
----------------------
Error Rate: 0.05455
Sensitivity: 0.95833
Specificity: 0.85714
Precision: 0.97872
Recall: 0.95833
F1 Score: 0.96842
True Positives: 46.0
True Negatives: 6.0
False Positives: 1.0
False Negatives: 2.0

Model (2 rules, depth = 2):

    sensitive
   /
Presence(AACTTGAGTAGGTTGATATGAACCTCACGAC)
   \
        resistant
       /
    Presence(AAAAAAATGAAGAGTGGCTTTTACCATATTG)
       \
        sensitive

