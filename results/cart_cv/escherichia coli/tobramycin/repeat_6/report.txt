Kover Learning Report
=====================

Running time: 1:25:33.991701

Configuration:
--------------
authorized_rules: 
bound_delta: 0.05
bound_max_genome_size: 10461658
class_importance: ['0.25', '0.5', '0.75', '1.0']
criterion: ['gini']
dataset: /scratch/adrouin/patric_data/single_species_datasets/tobramycin___7053822222416630118/dataset.kover
hp_choice: cv
max_depth: [20]
min_samples_split: [2]
n_cpu: 2
output_dir: /scratch/adrouin/patric_experiments/single_species_datasets/cart_cv/tobramycin___7053822222416630118/train_0.800_seed_5_10_folds
progress: False
split: train_0.800_seed_5_10_folds
verbose: False

Data summary:
-------------
Dataset file: /scratch/adrouin/patric_data/single_species_datasets/tobramycin___7053822222416630118/dataset.kover
Dataset UUID: 2ca1e864-05af-11e8-a59f-001b2193b764
Phenotype: Tobramycin___Escherichia_Coli___Metadata_Date_2018-01-29
Split: train_0.800_seed_5_10_folds
Number of genomes used for training: 338 (Group sensitive: 297, Group resistant: 41)
Number of genomes used for testing: 84 (Group sensitive: 75, Group resistant: 9)

Hyperparameter Values:
----------------------
Selection strategy: 10-fold cross-validation (score = 0.00891)
Criterion: gini
Class importance: class sensitive: 0.250, class resistant: 0.250
Maximum tree depth: 20
Minimum samples to split a node (examples): 2.000
Pruning alpha: 0.01255219

Metrics (training data)
-----------------------
Error Rate: 0.00592
Sensitivity: 1.0
Specificity: 0.99327
Precision: 0.95349
Recall: 1.0
F1 Score: 0.97619
True Positives: 41.0
True Negatives: 295.0
False Positives: 2.0
False Negatives: 0.0

Metrics (testing data)
----------------------
Error Rate: 0.04762
Sensitivity: 0.66667
Specificity: 0.98667
Precision: 0.85714
Recall: 0.66667
F1 Score: 0.75
True Positives: 6.0
True Negatives: 74.0
False Positives: 1.0
False Negatives: 3.0

Model (2 rules, depth = 2):

        sensitive
       /
    Presence(ATATCGCGATGCATACGCGGAAGGCAATAAC)
       \
        resistant
   /
Presence(AAACACGCCAGGCATTCGAGCGAACACGCAG)
   \
    resistant

